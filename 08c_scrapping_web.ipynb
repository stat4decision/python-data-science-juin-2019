{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer des données depuis le web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le web est un domaine riche en sources de données, vous avez forcément entendu parler de web scrapping pour récupérer des données sur le web.\n",
    "\n",
    "Le data scientist peut avoir besoin de récupérer des données sur Internet sans vouloir faire du développement web. Dans cette partie, deux approches seront examinées.\n",
    "\n",
    "Quelle que soit l’approche, Beautiful-Soup est un package central.\n",
    "\n",
    "Il va vous permettre de récupérer n’importe quel contenu HTML d’une page web et d’extraire de l’information de ce site web.\n",
    "\n",
    "Si par exemple, on désire scrapper un site, on va devoir commencer par inspecter le code html lié à ce site. Si on désire récupérer tous les noms de package d’un article sur les packages Python pour la data science, on va devoir identifier la balise liée à ces noms et ensuite on pourra commencer à travailler en Python.\n",
    "\n",
    "En inspectant le code html, on trouve ce code :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<div class=\"x-accordion-heading\"><a id=\"tab-5b02e7bbbe1a3\" class=\"xaccordion-\n",
    "toggle collapsed\" role=\"tab\" data-x-toggle=\"collapse-b\"\n",
    "data-x-toggleable=\"5b02e7bbbe1a3\" data-x-toggle-group=\"5b02e7bbbe08d\"\n",
    "aria-selected=\"false\" aria-expanded=\"false\" aria-controls=\"panel-\n",
    "5b02e7bbbe1a3\">Jupyter Notebook, une interface plus intuitive</a></\n",
    "div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble que la balise de division div de ce que l’on cherche se nomme *x-accordion-\n",
    "heading*. \n",
    "\n",
    "On va donc utiliser Python pour récupérer le contenu de la page :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html class=\"no-js\" lang=\"fr-F\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "url = 'https://www.stat4decision.com/fr/packages-python-data-science/'\n",
    "reponse = get(url)\n",
    "print(reponse.text[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet reponse que l’on a créé est un objet requests.models.Response.\n",
    "On va ensuite extraire de cette page les balises div du type recherché :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "# on crée un objet en utlisant le parser Python\n",
    "html_soup = BeautifulSoup(reponse.text, 'html.parser')\n",
    "# on recherche la div qui nous intéresse\n",
    "noms_packages = html_soup.find_all('div', class_='x-accordion-heading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans noms_packages, on a tout ce qui se trouve dans le titre de chaque division.\n",
    "\n",
    "Nous allons maintenant extraire de cet élément les noms des packages qui se trouvent au début de chaque titre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter notebook\n",
      "Numpy\n",
      "Scipy\n",
      "Pandas\n",
      "Statsmodels\n",
      "Scikit-learn\n",
      "Matplotlib\n",
      "Bokeh\n",
      "Seaborn\n",
      "Keras\n"
     ]
    }
   ],
   "source": [
    "# on fait une boucle sur les éléments de l’objet créé\n",
    "for div_nom in noms_packages :\n",
    "    # on affiche avec une majuscule en première lettre les\n",
    "    # premiers mots avant une virgule\n",
    "    print(div_nom.text.split(\",\")[0].capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc récupéré automatiquement les valeurs textuelles qui nous intéressent.\n",
    "\n",
    "Il ne s’agit pas ici de développer plus de notions liées au langage html mais si vous désirez aller plus loin de ce côté-là il vous faudra quelques bases.\n",
    "\n",
    "Si votre objectif est de directement charger des tableaux dans des objets DataFrame, les choses se simplifient. Pandas, combiné à Beautiful-Soup, fait une grande partie du travail pour vous.\n",
    "\n",
    "Imaginons que l’on désire récupérer des données sportives, par exemple de tennis, nous allons utiliser les données de Wikipédia sur le tennis et essayer de stocker les informations sur les tournois du grand chelem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
